{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPT-2 Adoption\n",
    "\n",
    "Code from https://github.com/graykode/gpt-2-Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import torch\n",
    "import math\n",
    "import torch.nn as nn\n",
    "from torch.nn.parameter import Parameter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# Reproducibility\n",
    "seed = random.randint(0, 2147483647)\n",
    "np.random.seed(seed)\n",
    "torch.random.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "\n",
    "# GPU or CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### \n",
    "# GPTConfig - HuggingFace style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPT2Config(object):\n",
    "    def __init__(\n",
    "            self,\n",
    "            vocab_size_or_config_json_file=50257,\n",
    "            n_positions=1024,\n",
    "            n_ctx=1024,\n",
    "            n_embd=768,\n",
    "            n_layer=12,\n",
    "            n_head=12,\n",
    "            layer_norm_epsilon=1e-5,\n",
    "            initializer_range=0.02,\n",
    "            pdrop=0.1,\n",
    "    ):\n",
    "        self.vocab_size = vocab_size_or_config_json_file\n",
    "        self.n_ctx = n_ctx\n",
    "        self.n_positions = n_positions\n",
    "        self.n_embd = n_embd\n",
    "        self.n_layer = n_layer\n",
    "        self.n_head = n_head\n",
    "        self.layer_norm_epsilon = layer_norm_epsilon\n",
    "        self.initializer_range = initializer_range\n",
    "        self.pdrop = pdrop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### \n",
    "# Wandb managing experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtst008\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/tst008/PACT-replica/runs/1nanxec6\" target=\"_blank\">laced-glade-16</a></strong> to <a href=\"https://wandb.ai/tst008/PACT-replica\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W&B online, running your script from this directory will now sync to the cloud.\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "is_experimenting = False\n",
    "\n",
    "if is_experimenting:\n",
    "    wandb.init(project=\"PACT-replica\", entity=\"tst008\")\n",
    "    !wandb on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### \n",
    "# Creating Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Layer Norm: $y = \\frac{x-E[x]}{\\sqrt{Var[x] + \\epsilon}} * \\gamma + \\beta$\n",
    "\n",
    "- Where x is a mini-batch of input, with dimension `normalized_shape`.\n",
    "- $\\gamma$ and $\\beta$ are $\\textit{learnable}$ affine transform parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, hidden_size, eps=1e-12):\n",
    "        \"\"\"Construct a layernorm module in the TF style (epsilon inside the square root).\n",
    "        \"\"\"\n",
    "        super(LayerNorm, self).__init__()\n",
    "        self.weight = nn.Parameter(torch.ones(hidden_size))\n",
    "        self.bias = nn.Parameter(torch.zeros(hidden_size))\n",
    "        self.variance_epsilon = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        u = x.mean(-1, keepdim=True)\n",
    "        s = (x - u).pow(2).mean(-1, keepdim=True)\n",
    "        x = (x - u) / torch.sqrt(s + self.variance_epsilon)\n",
    "        return self.weight * x + self.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 5, 10])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch, sentence_length, embedding_dim = 20, 5, 10\n",
    "embedding = torch.randn(batch, sentence_length, embedding_dim)\n",
    "layer_norm = LayerNorm(embedding_dim)\n",
    "layer_norm(embedding).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Input: $N, C, L$, Output: $N, C, L_o$\n",
    "\n",
    "$out(N, C_j) =  bias(C_j) + \\sum^{C_i - 1}_{k=1}w(C_j, k) * inp(N_i, k)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv1D(nn.Module):\n",
    "    def __init__(self, nf, nx):\n",
    "        super(Conv1D, self).__init__()\n",
    "        self.nf = nf\n",
    "        self.nx = nx\n",
    "        w = torch.empty(nx, nf)\n",
    "        nn.init.normal_(w, std=0.02)\n",
    "        self.weight = Parameter(w)\n",
    "        self.bias = Parameter(torch.zeros(nf))\n",
    "\n",
    "    def forward(self, x):\n",
    "        assert self.nx == x.shape[-1], f\"Shape mismatched, expected shape: {list(x.shape[:-1])+[self.nx]}, got shape: {list(x.shape)}\"\n",
    "        size_out = x.size()[:-1] + (self.nf,)\n",
    "        x = torch.addmm(self.bias, x.view(-1, x.size(-1)), self.weight)\n",
    "        x = x.view(*size_out)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 16, 10])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = Conv1D(10, 50)\n",
    "i = torch.randn(20, 16, 50)\n",
    "m(i).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applies multi-head attention \n",
    "\n",
    "- Query: representation of current word used to score against other words\n",
    "- Key: labels for all potentially relevant words in segment\n",
    "- Value: Actual word representations. Relevancy of each word is added up to represent current word\n",
    "\n",
    "Input size, output size??\n",
    "https://jalammar.github.io/illustrated-gpt2/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, nx, n_ctx, config, scale=False):\n",
    "        super(Attention, self).__init__()\n",
    "        n_state = nx  # in Attention: n_state=768 (nx=n_embd)\n",
    "        # [switch nx => n_state from Block to Attention to keep identical to TF implem]\n",
    "        assert n_state % config.n_head == 0\n",
    "        self.register_buffer(\"bias\", torch.tril(torch.ones(n_ctx, n_ctx)).view(1, 1, n_ctx, n_ctx))\n",
    "        self.n_head = config.n_head\n",
    "        self.split_size = n_state\n",
    "        self.scale = scale\n",
    "        self.c_attn = Conv1D(n_state * 3, nx)\n",
    "        self.c_proj = Conv1D(n_state, nx)\n",
    "        self.attn_drop = nn.Dropout(config.pdrop, inplace=False)\n",
    "        self.resid_drop = nn.Dropout(config.pdrop, inplace=False)\n",
    "\n",
    "    def _attn(self, q, k, v):\n",
    "        w = torch.matmul(q, k)\n",
    "        if self.scale:\n",
    "            w = w / math.sqrt(v.size(-1))\n",
    "        nd, ns = w.size(-2), w.size(-1)\n",
    "        try:\n",
    "            b = self.bias[:, :, ns-nd:ns, :ns]\n",
    "            w = w * b - 1e10 * (1 - b)\n",
    "            w = nn.Softmax(dim=-1)(w)\n",
    "        except:\n",
    "            print(b.shape, w.shape)\n",
    "            raise\n",
    "        return w, torch.matmul(w, v)\n",
    "\n",
    "    def merge_heads(self, x):\n",
    "        x = x.permute(0, 2, 1, 3).contiguous()\n",
    "        new_x_shape = x.size()[:-2] + (x.size(-2) * x.size(-1),)\n",
    "        return x.view(*new_x_shape)  # in Tensorflow implem: fct merge_states\n",
    "\n",
    "    def split_heads(self, x, k=False):\n",
    "        new_x_shape = x.size()[:-1] + (self.n_head, x.size(-1) // self.n_head)\n",
    "        x = x.view(*new_x_shape)  # in Tensorflow implem: fct split_states\n",
    "        if k:\n",
    "            return x.permute(0, 2, 3, 1)  # (batch, head, head_features, seq_length)\n",
    "        else:\n",
    "            return x.permute(0, 2, 1, 3)  # (batch, head, seq_length, head_features)\n",
    "\n",
    "    def forward(self, x, layer_past=None):\n",
    "        # Begin by looking at the shape of all these\n",
    "#         print(f\"x:{x.shape}\")\n",
    "        x = self.c_attn(x)\n",
    "#         print(f\"(after c_attn) x:{x.shape}\")\n",
    "        query, key, value = x.split(self.split_size, dim=2)\n",
    "#         print(f\"query:{query.shape}, key:{key.shape}, value:{value.shape},\")\n",
    "        query = self.split_heads(query)\n",
    "        key = self.split_heads(key, k=True)\n",
    "        value = self.split_heads(value)\n",
    "#         print(f\"(after split_heads()) query:{query.shape}, key:{key.shape}, value:{value.shape},\")\n",
    "        if layer_past is not None:\n",
    "            past_key, past_value = layer_past[0].transpose(-2, -1), layer_past[1]  # transpose back cf below\n",
    "            key = torch.cat((past_key, key), dim=-1)\n",
    "            value = torch.cat((past_value, value), dim=-2)\n",
    "#             print(f\"(in if layer_past is not None) query:{query.shape}, key:{key.shape}, value:{value.shape},\")\n",
    "        present = torch.stack((key.transpose(-2, -1), value))  # transpose to have same shapes for stacking\n",
    "#         print(f\"present:{present.shape}\")\n",
    "        w, a = self._attn(query, key, value)\n",
    "#         print(f\"(output of _attn) a:{a.shape}\")\n",
    "        a = self.merge_heads(a)\n",
    "#         print(f\"(output of merge_heads) a:{a.shape}\")\n",
    "        a = self.c_proj(a)\n",
    "#         print(f\"(output of c_proj) a:{a.shape}\")\n",
    "        a = self.resid_drop(a)\n",
    "#         print(f\"(output of resid_drop) a:{a.shape}\")\n",
    "        return a, present, w # Present key and values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Test Masked before softmax, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1024, 1024)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = torch.ones([1, 1, 1024, 1024]) #torch.Size([1, 12, 1760, 1760])\n",
    "b = torch.ones([1, 12,])\n",
    "nd, ns = w.size(-2), w.size(-1)\n",
    "nd, ns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applies the Gaussian Error Linear Units function:\n",
    "    \n",
    "$y = x * \\Phi(x)$\n",
    "\n",
    "where $\\Phi(x)$ is the Cumulative Distribution Function for Gaussian Distribution\n",
    "\n",
    "... tho I'm not seeing that here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gelu(x):\n",
    "    return 0.5 * x * (1 + torch.tanh(math.sqrt(2 / math.pi) * (x + 0.044715 * torch.pow(x, 3))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.1160,  1.3173])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gelu(torch.randn(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conv1D(n_state, n_embd) $\\implies$ gelu $\\implies$ Conv1D(n_embd, n_state)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, n_state, config):  # in MLP: n_state=3072 (4 * n_embd)\n",
    "        super(MLP, self).__init__()\n",
    "        nx = config.n_embd\n",
    "        self.c_fc = Conv1D(n_state, nx)\n",
    "        self.c_proj = Conv1D(nx, n_state)\n",
    "        self.act = gelu\n",
    "        self.dropout = nn.Dropout(config.pdrop)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.act(self.c_fc(x))\n",
    "        h2 = self.c_proj(h)\n",
    "        h2 = self.dropout(h2)\n",
    "        return h2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 3, 15])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import argparse\n",
    "config = argparse.Namespace(\n",
    "    n_embd = 15,\n",
    "    pdrop = .1,\n",
    ")\n",
    "i = torch.randn(10, 3, 15)\n",
    "mlp = MLP(30, config)\n",
    "mlp(i).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Returns: \n",
    "- $x + (LN(x) \\implies ATTN(x)) + MLP(x)$\n",
    "- `present` the cumulative keys and values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    def __init__(self, n_ctx, config, scale=False):\n",
    "        super(Block, self).__init__()\n",
    "        nx = config.n_embd\n",
    "        self.ln_1 = LayerNorm(nx, eps=config.layer_norm_epsilon)\n",
    "        self.attn = Attention(nx, n_ctx, config, scale)\n",
    "        self.ln_2 = LayerNorm(nx, eps=config.layer_norm_epsilon)\n",
    "        self.mlp = MLP(4 * nx, config)\n",
    "\n",
    "    def forward(self, x, layer_past=None):\n",
    "        a, present, _ = self.attn(self.ln_1(x), layer_past=layer_past)\n",
    "        x = x + a\n",
    "        m = self.mlp(self.ln_2(x))\n",
    "        x = x + m\n",
    "        return x, present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Test Block"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decoder-only Transformer GPT-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPT2Model(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(GPT2Model, self).__init__()\n",
    "        self.n_layer = config.n_layer\n",
    "        self.n_embd = config.n_embd\n",
    "        self.n_vocab = config.vocab_size\n",
    "\n",
    "        self.wte = nn.Embedding(config.vocab_size, config.n_embd)\n",
    "        self.wpe = nn.Embedding(config.n_positions, config.n_embd)\n",
    "        \n",
    "        self.drop = nn.Dropout(config.pdrop, inplace=False)\n",
    "        \n",
    "        block = Block(config.n_ctx, config, scale=True)\n",
    "        self.h = nn.ModuleList([copy.deepcopy(block) for _ in range(config.n_layer)])\n",
    "        self.ln_f = LayerNorm(config.n_embd, \n",
    "                              eps=config.layer_norm_epsilon)\n",
    "\n",
    "    def set_embeddings_weights(self, model_embeddings_weights):\n",
    "        embed_shape = model_embeddings_weights.shape\n",
    "        self.decoder = nn.Linear(embed_shape[1], embed_shape[0], bias=False)\n",
    "        self.decoder.weight = model_embeddings_weights  # Tied weights\n",
    "\n",
    "    def forward(self, input_ids, \n",
    "                position_ids=None, \n",
    "                token_type_ids=None, \n",
    "                past=None):\n",
    "        if past is None:\n",
    "            past_length = 0\n",
    "            past = [None] * len(self.h)\n",
    "        else:\n",
    "            past_length = past[0][0].size(-2)\n",
    "        if position_ids is None:\n",
    "            position_ids = torch.arange(past_length, input_ids.size(-1) + past_length, dtype=torch.long,\n",
    "                                        device=input_ids.device)\n",
    "            position_ids = position_ids.unsqueeze(0).expand_as(input_ids)\n",
    "\n",
    "        input_shape = input_ids.size()\n",
    "        input_ids = input_ids.view(-1, input_ids.size(-1))\n",
    "        position_ids = position_ids.view(-1, position_ids.size(-1))\n",
    "\n",
    "        inputs_embeds = self.wte(input_ids)\n",
    "        position_embeds = self.wpe(position_ids)\n",
    "        if token_type_ids is not None:\n",
    "            token_type_ids = token_type_ids.view(-1, token_type_ids.size(-1))\n",
    "            token_type_embeds = self.wte(token_type_ids)\n",
    "        else:\n",
    "            token_type_embeds = 0\n",
    "        hidden_states = inputs_embeds + position_embeds + token_type_embeds\n",
    "        presents = []\n",
    "        for block, layer_past in zip(self.h, past):\n",
    "            hidden_states, present = block(hidden_states, layer_past)\n",
    "            presents.append(present)\n",
    "        hidden_states = self.drop(hidden_states)\n",
    "        hidden_states = self.ln_f(hidden_states)\n",
    "        output_shape = input_shape + (hidden_states.size(-1),)\n",
    "        return hidden_states.view(*output_shape), presents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Initial test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPT2LMHead(nn.Module):\n",
    "    def __init__(self, model_embeddings_weights, config):\n",
    "        super(GPT2LMHead, self).__init__()\n",
    "        self.n_embd = config.n_embd\n",
    "        self.set_embeddings_weights(model_embeddings_weights)\n",
    "\n",
    "    def set_embeddings_weights(self, model_embeddings_weights):\n",
    "        embed_shape = model_embeddings_weights.shape\n",
    "        self.decoder = nn.Linear(embed_shape[1], embed_shape[0], bias=False)\n",
    "        self.decoder.weight = model_embeddings_weights  # Tied weights\n",
    "\n",
    "    def forward(self, hidden_state):\n",
    "        # Truncated Language modeling logits (we remove the last token)\n",
    "        # h_trunc = h[:, :-1].contiguous().view(-1, self.n_embd)\n",
    "        lm_logits = self.decoder(hidden_state)\n",
    "        return lm_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPT2LMHeadModel(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(GPT2LMHeadModel, self).__init__()\n",
    "        self.transformer = GPT2Model(config)\n",
    "        self.lm_head = GPT2LMHead(self.transformer.wte.weight, config)\n",
    "\n",
    "    def set_tied(self):\n",
    "        \"\"\" Make sure we are sharing the embeddings\n",
    "        \"\"\"\n",
    "        self.lm_head.set_embeddings_weights(self.transformer.wte.weight)\n",
    "\n",
    "    def forward(self, input_ids, position_ids=None, token_type_ids=None, lm_labels=None, past=None):\n",
    "        hidden_states, presents = self.transformer(input_ids, position_ids, token_type_ids, past)\n",
    "        lm_logits = self.lm_head(hidden_states)\n",
    "#         print_tensor(lm_logits)\n",
    "        if lm_labels is not None:\n",
    "            shift_logits = lm_logits[..., :-1, :].contiguous()\n",
    "            shift_labels = lm_labels[..., 1:].contiguous()\n",
    "            loss_fct = nn.CrossEntropyLoss()\n",
    "#             loss_fct = nn.CrossEntropyLoss(ignore_index=-1)\n",
    "#             loss = loss_fct(lm_logits.view(-1, lm_logits.size(-1)), lm_labels.view(-1))\n",
    "#             print_tensor(shift_labels.view(-1))\n",
    "#             print_tensor(shift_logits.view(-1, shift_logits.size(-1)))\n",
    "            loss = loss_fct(shift_logits.view(-1, shift_logits.size(-1)), shift_labels.view(-1))\n",
    "            return loss, lm_logits, presents\n",
    "        return lm_logits, presents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_tensor(t):\n",
    "    print(t.shape, end=\",\")\n",
    "    print(torch.max(t), torch.min(t), torch.mean(t), end=\",\")\n",
    "    print(torch.sum(torch.isnan(t)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### \n",
    "# Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import regex as re\n",
    "from os.path import expanduser\n",
    "# from functools import lru_cache\n",
    "\n",
    "# @lru_cache()\n",
    "def bytes_to_unicode():\n",
    "    \"\"\"\n",
    "    Returns list of utf-8 byte and a corresponding list of unicode strings.\n",
    "    The reversible bpe codes work on unicode strings.\n",
    "    This means you need a large # of unicode characters in your vocab if you want to avoid UNKs.\n",
    "    When you're at something like a 10B token dataset you end up needing around 5K for decent coverage.\n",
    "    This is a signficant percentage of your normal, say, 32K bpe vocab.\n",
    "    To avoid that, we want lookup tables between utf-8 bytes and unicode strings.\n",
    "    And avoids mapping to whitespace/control characters the bpe code barfs on.\n",
    "    \"\"\"\n",
    "    bs = list(range(ord(\"!\"), ord(\"~\")+1))+list(range(ord(\"¡\"), ord(\"¬\")+1))+list(range(ord(\"®\"), ord(\"ÿ\")+1))\n",
    "    cs = bs[:]\n",
    "    n = 0\n",
    "    for b in range(2**8):\n",
    "        if b not in bs:\n",
    "            bs.append(b)\n",
    "            cs.append(2**8+n)\n",
    "            n += 1\n",
    "    cs = [chr(n) for n in cs]\n",
    "    return dict(zip(bs, cs))\n",
    "\n",
    "def get_pairs(word):\n",
    "    \"\"\"Return set of symbol pairs in a word.\n",
    "    Word is represented as tuple of symbols (symbols being variable-length strings).\n",
    "    \"\"\"\n",
    "    pairs = set()\n",
    "    prev_char = word[0]\n",
    "    for char in word[1:]:\n",
    "        pairs.add((prev_char, char))\n",
    "        prev_char = char\n",
    "    return pairs\n",
    "\n",
    "class Encoder:\n",
    "    def __init__(self, encoder, bpe_merges, errors='replace'):\n",
    "        self.encoder = encoder\n",
    "        self.decoder = {v:k for k,v in self.encoder.items()}\n",
    "        self.errors = errors # how to handle errors in decoding\n",
    "        self.byte_encoder = bytes_to_unicode()\n",
    "        self.byte_decoder = {v:k for k, v in self.byte_encoder.items()}\n",
    "        self.bpe_ranks = dict(zip(bpe_merges, range(len(bpe_merges))))\n",
    "        self.cache = {}\n",
    "        self.special_tokens = []\n",
    "\n",
    "        # Should haved added re.IGNORECASE so BPE merges can happen for capitalized versions of contractions\n",
    "        self.re_pattern = r\"\"\"'s|'t|'re|'ve|'m|'ll|'d| ?\\p{L}+| ?\\p{N}+| ?[^\\s\\p{L}\\p{N}]+|\\s+(?!\\S)|\\s+\"\"\"\n",
    "        self.pat = re.compile(self.re_pattern)\n",
    "        \n",
    "    def add_special_token(self, s):\n",
    "        if s in self.special_tokens:\n",
    "            print(f\"Token {s} already added\")\n",
    "        self.special_tokens.append(s)\n",
    "        if s in self.encoder: \n",
    "            # Special token already known, but regex pattern cannot capture fully yet\n",
    "            pass\n",
    "        else:\n",
    "            id = len(self.encoder)\n",
    "            self.encoder[s] = id\n",
    "            self.decoder[id] = s\n",
    "        s = s.replace(\"|\", r\"\\|\")\n",
    "        self.re_pattern = \" \" + s + \"|\" + self.re_pattern\n",
    "        self.pat = re.compile(self.re_pattern)\n",
    "\n",
    "    def bpe(self, token):\n",
    "        # Also don't split on special tokens\n",
    "#         print(token, token in self.special_tokens)\n",
    "        if token in self.special_tokens:\n",
    "            return token\n",
    "        if token in self.cache:\n",
    "            return self.cache[token]\n",
    "        word = tuple(token)\n",
    "        pairs = get_pairs(word)\n",
    "\n",
    "        if not pairs:\n",
    "            return token\n",
    "\n",
    "        while True:\n",
    "            bigram = min(pairs, key = lambda pair: self.bpe_ranks.get(pair, float('inf')))\n",
    "            if bigram not in self.bpe_ranks:\n",
    "                break\n",
    "            first, second = bigram\n",
    "            new_word = []\n",
    "            i = 0\n",
    "            while i < len(word):\n",
    "                try:\n",
    "                    j = word.index(first, i)\n",
    "                    new_word.extend(word[i:j])\n",
    "                    i = j\n",
    "                except:\n",
    "                    new_word.extend(word[i:])\n",
    "                    break\n",
    "\n",
    "                if word[i] == first and i < len(word)-1 and word[i+1] == second:\n",
    "                    new_word.append(first+second)\n",
    "                    i += 2\n",
    "                else:\n",
    "                    new_word.append(word[i])\n",
    "                    i += 1\n",
    "            new_word = tuple(new_word)\n",
    "            word = new_word\n",
    "            if len(word) == 1:\n",
    "                break\n",
    "            else:\n",
    "                pairs = get_pairs(word)\n",
    "        word = ' '.join(word)\n",
    "        self.cache[token] = word\n",
    "        return word\n",
    "\n",
    "    def encode(self, text):\n",
    "        bpe_tokens = []\n",
    "        for token in re.findall(self.pat, text):\n",
    "#             print(token.lstrip())\n",
    "            if token.lstrip() in self.special_tokens:\n",
    "                token = token.lstrip()\n",
    "            else:\n",
    "                token = ''.join(self.byte_encoder[b] for b in token.encode('utf-8'))\n",
    "            bpe_tokens.extend(self.encoder[bpe_token] for bpe_token in self.bpe(token).split(' '))\n",
    "        return bpe_tokens\n",
    "\n",
    "    def decode(self, tokens):\n",
    "        text = ''.join([self.decoder[token] for token in tokens])\n",
    "        text = bytearray([self.byte_decoder[c] for c in text]).decode('utf-8', errors=self.errors)\n",
    "        return text\n",
    "\n",
    "def get_encoder():\n",
    "    home = expanduser(\"~\")\n",
    "    with open(os.path.join(home, 'data/GPT2/encoder.json'), 'r') as f:\n",
    "        encoder = json.load(f)\n",
    "    with open(os.path.join(home, 'data/GPT2/vocab.bpe'), 'r', encoding=\"utf-8\") as f:\n",
    "        bpe_data = f.read()\n",
    "    bpe_merges = [tuple(merge_str.split()) for merge_str in bpe_data.split('\\n')[1:-1]]\n",
    "    enc = Encoder(\n",
    "        encoder=encoder,\n",
    "        bpe_merges=bpe_merges,\n",
    "    )\n",
    "#     print(\"<|endoftext|>\" in enc.encoder)\n",
    "    enc.add_special_token(\"<|endoftext|>\")\n",
    "    enc.add_special_token(\"<|GOAL|>\")\n",
    "    enc.add_special_token(\"<|PROOFSTEP|>\")\n",
    "    print(enc.special_tokens)\n",
    "    return enc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### \n",
    "# Sampling a sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from tqdm import trange\n",
    "\n",
    "def top_k_logits(logits, k):\n",
    "    if k == 0:\n",
    "        return logits\n",
    "    values, _ = torch.topk(logits, k)\n",
    "    min_values = values[:, -1]\n",
    "    return torch.where(logits < min_values, torch.ones_like(logits, dtype=logits.dtype) * -1e10, logits)\n",
    "\n",
    "def sample_sequence(model, length, start_token=None, batch_size=None, context=None, temperature=1, top_k=0, device='cuda', sample=True):\n",
    "    if start_token is None:\n",
    "        assert context is not None, 'Specify exactly one of start_token and context!'\n",
    "        context = torch.tensor(context, device=device, dtype=torch.long).unsqueeze(0).repeat(batch_size, 1)\n",
    "    else:\n",
    "        assert context is None, 'Specify exactly one of start_token and context!'\n",
    "        context = torch.full((batch_size, 1), start_token, device=device, dtype=torch.long)\n",
    "    prev = context\n",
    "    output = context\n",
    "    past = None\n",
    "    with torch.no_grad():\n",
    "        for i in range(length):\n",
    "#             print(prev.shape)\n",
    "#             raise\n",
    "            logits, past = model(prev, past=past)\n",
    "            logits = logits[:, -1, :] / temperature\n",
    "            logits = top_k_logits(logits, k=top_k)\n",
    "            log_probs = F.softmax(logits, dim=-1)\n",
    "            if sample:\n",
    "                prev = torch.multinomial(log_probs, num_samples=1)\n",
    "            else:\n",
    "                _, prev = torch.topk(log_probs, k=1, dim=-1)\n",
    "            output = torch.cat((output, prev), dim=1)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vocab_size_or_config_json_file=50257,\n",
    "n_positions=1024,\n",
    "n_ctx=1024,\n",
    "n_embd=768,\n",
    "n_layer=12,\n",
    "n_head=12,\n",
    "layer_norm_epsilon=1e-5,\n",
    "initializer_range=0.02,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use an 80-5-15 train-validation-test split. We split all\n",
    "datapoints deterministically by theorem name, by hashing\n",
    "each name to a float in (0, 1)\n",
    "\n",
    "For fine-tuning a model, we load saved parameters but reinitialize the optimizer. We start each training for a fixed\n",
    "number of tokens (defining the cosine schedule) and record\n",
    "the number of tokens consumed as we reach a minimal validation loss. We use the minimum validation loss snapshot\n",
    "to evaluate each model on our held-out test set.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### \n",
    "# Fine Tuning\n",
    "\n",
    "https://towardsdatascience.com/how-to-fine-tune-gpt-2-for-text-generation-ae2ea53bc272"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200298\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>goal_pp</th>\n",
       "      <th>decl_name</th>\n",
       "      <th>open_namespaces</th>\n",
       "      <th>filename</th>\n",
       "      <th>line</th>\n",
       "      <th>column</th>\n",
       "      <th>proof_key</th>\n",
       "      <th>human_tactic_code</th>\n",
       "      <th>tactic_class</th>\n",
       "      <th>cleaned_goal</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>α : Type u,\\n_inst_1 : inhabited α,\\nb : buffe...</td>\n",
       "      <td>buffer.read_eq_read'</td>\n",
       "      <td>buffer</td>\n",
       "      <td>lean/library/data/buffer.lean</td>\n",
       "      <td>49</td>\n",
       "      <td>30</td>\n",
       "      <td>lean/library/data/buffer.lean:49:1</td>\n",
       "      <td>cases b; unfold read read'; simp [array.read_e...</td>\n",
       "      <td>semicolon</td>\n",
       "      <td>α : Type u,\\t_inst_1 : inhabited α,\\tb : buffe...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>α : Type u,\\n_inst_1 : inhabited α,\\nb : buffe...</td>\n",
       "      <td>buffer.read_eq_read'</td>\n",
       "      <td>buffer</td>\n",
       "      <td>lean/library/data/buffer.lean</td>\n",
       "      <td>49</td>\n",
       "      <td>11</td>\n",
       "      <td>lean/library/data/buffer.lean:49:1</td>\n",
       "      <td>cases b; unfold read read'</td>\n",
       "      <td>semicolon</td>\n",
       "      <td>α : Type u,\\t_inst_1 : inhabited α,\\tb : buffe...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>α : Type u,\\n_inst_1 : inhabited α,\\ni b_fst :...</td>\n",
       "      <td>buffer.read_eq_read'</td>\n",
       "      <td>buffer</td>\n",
       "      <td>lean/library/data/buffer.lean</td>\n",
       "      <td>49</td>\n",
       "      <td>13</td>\n",
       "      <td>lean/library/data/buffer.lean:49:1</td>\n",
       "      <td>unfold read read'</td>\n",
       "      <td>named</td>\n",
       "      <td>α : Type u,\\t_inst_1 : inhabited α,\\ti b_fst :...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>α : Type u,\\n_inst_1 : inhabited α,\\ni b_fst :...</td>\n",
       "      <td>buffer.read_eq_read'</td>\n",
       "      <td>buffer</td>\n",
       "      <td>lean/library/data/buffer.lean</td>\n",
       "      <td>49</td>\n",
       "      <td>32</td>\n",
       "      <td>lean/library/data/buffer.lean:49:1</td>\n",
       "      <td>simp [array.read_eq_read']</td>\n",
       "      <td>named</td>\n",
       "      <td>α : Type u,\\t_inst_1 : inhabited α,\\ti b_fst :...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>α : Type u,\\n_inst_1 : inhabited α,\\nb : buffe...</td>\n",
       "      <td>buffer.read_eq_read'</td>\n",
       "      <td>buffer</td>\n",
       "      <td>lean/library/data/buffer.lean</td>\n",
       "      <td>49</td>\n",
       "      <td>4</td>\n",
       "      <td>lean/library/data/buffer.lean:49:1</td>\n",
       "      <td>cases b</td>\n",
       "      <td>named</td>\n",
       "      <td>α : Type u,\\t_inst_1 : inhabited α,\\tb : buffe...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                            goal_pp  \\\n",
       "0           0  α : Type u,\\n_inst_1 : inhabited α,\\nb : buffe...   \n",
       "1           1  α : Type u,\\n_inst_1 : inhabited α,\\nb : buffe...   \n",
       "2           2  α : Type u,\\n_inst_1 : inhabited α,\\ni b_fst :...   \n",
       "3           3  α : Type u,\\n_inst_1 : inhabited α,\\ni b_fst :...   \n",
       "4           4  α : Type u,\\n_inst_1 : inhabited α,\\nb : buffe...   \n",
       "\n",
       "              decl_name open_namespaces                       filename  line  \\\n",
       "0  buffer.read_eq_read'          buffer  lean/library/data/buffer.lean    49   \n",
       "1  buffer.read_eq_read'          buffer  lean/library/data/buffer.lean    49   \n",
       "2  buffer.read_eq_read'          buffer  lean/library/data/buffer.lean    49   \n",
       "3  buffer.read_eq_read'          buffer  lean/library/data/buffer.lean    49   \n",
       "4  buffer.read_eq_read'          buffer  lean/library/data/buffer.lean    49   \n",
       "\n",
       "   column                           proof_key  \\\n",
       "0      30  lean/library/data/buffer.lean:49:1   \n",
       "1      11  lean/library/data/buffer.lean:49:1   \n",
       "2      13  lean/library/data/buffer.lean:49:1   \n",
       "3      32  lean/library/data/buffer.lean:49:1   \n",
       "4       4  lean/library/data/buffer.lean:49:1   \n",
       "\n",
       "                                   human_tactic_code tactic_class  \\\n",
       "0  cases b; unfold read read'; simp [array.read_e...    semicolon   \n",
       "1                         cases b; unfold read read'    semicolon   \n",
       "2                                  unfold read read'        named   \n",
       "3                         simp [array.read_eq_read']        named   \n",
       "4                                            cases b        named   \n",
       "\n",
       "                                        cleaned_goal split  \n",
       "0  α : Type u,\\t_inst_1 : inhabited α,\\tb : buffe...  test  \n",
       "1  α : Type u,\\t_inst_1 : inhabited α,\\tb : buffe...  test  \n",
       "2  α : Type u,\\t_inst_1 : inhabited α,\\ti b_fst :...  test  \n",
       "3  α : Type u,\\t_inst_1 : inhabited α,\\ti b_fst :...  test  \n",
       "4  α : Type u,\\t_inst_1 : inhabited α,\\tb : buffe...  test  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"data/data_and_metadata.csv\")\n",
    "print(len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<|endoftext|>', '<|GOAL|>', '<|PROOFSTEP|>']\n"
     ]
    }
   ],
   "source": [
    "# Initialize encoder / tokenizer\n",
    "enc = get_encoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 37988 indices\n"
     ]
    }
   ],
   "source": [
    "import regex as re\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import trange\n",
    "import numpy as np\n",
    "\n",
    "prev_length = len(df)\n",
    "df = df[df.goal_pp.apply(lambda x: not pd.isna(x))]\n",
    "df = df[df[\"tactic_class\"] == \"named\"]\n",
    "df = df.reset_index()\n",
    "print(f\"Dropped {prev_length - len(df)} indices\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 162310/162310 [01:04<00:00, 2519.99it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check for un-tokenizable pretty printed goals\n",
    "goal_lengths = []\n",
    "for i in trange(len(df)):\n",
    "    try:\n",
    "        tokens = enc.encode(df.cleaned_goal[i])\n",
    "        if enc.decode(tokens) != df.cleaned_goal[i]:\n",
    "            print(\"shit\")\n",
    "            break\n",
    "        goal_lengths.append(len(tokens))\n",
    "    except:\n",
    "        print(f\"Error at {i}, where text is {df.cleaned_goal[i]} with type {type(df.cleaned_goal[i])}\")\n",
    "        raise\n",
    "sns.distplot(goal_lengths)\n",
    "plt.title(\"Goal length distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 162310/162310 [00:11<00:00, 13550.56it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check for un-tokenizable human written tactics\n",
    "tactic_lengths = []\n",
    "for i in trange(len(df)):\n",
    "    try:\n",
    "        tokens = enc.encode(df.human_tactic_code[i])\n",
    "        if enc.decode(tokens) != df.human_tactic_code[i]:\n",
    "            print(\"shit\")\n",
    "            break\n",
    "        tactic_lengths.append(len(tokens))\n",
    "    except:\n",
    "        print(f\"Error at {i}, where text is {df.human_tactic_code[i]} with type {type(df.human_tactic_code[i])}\")\n",
    "        raise\n",
    "sns.distplot(tactic_lengths)\n",
    "plt.title(\"Tactic length distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.array(goal_lengths) == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of indices to be kept will be 160374 in a total of 162310\n",
      "Length before: 162310\n",
      "Length after: 160374\n"
     ]
    }
   ],
   "source": [
    "keep_indices = []\n",
    "for i in range(len(goal_lengths)):\n",
    "    if goal_lengths[i] + tactic_lengths[i] + 3 <= 1024:\n",
    "        keep_indices.append(i)\n",
    "print(f\"Number of indices to be kept will be {len(keep_indices)} in a total of {len(goal_lengths)}\")\n",
    "\n",
    "print(f\"Length before: {len(df)}\")\n",
    "df = df.iloc[keep_indices, :]\n",
    "df.reset_index()\n",
    "print(f\"Length after: {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "147271\n",
      "6317\n",
      "6786\n"
     ]
    }
   ],
   "source": [
    "print(len(df[df.split == 'train']))\n",
    "print(len(df[df.split == 'test']))\n",
    "print(len(df[df.split == 'valid']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "# Put goal and tactic into one place, extend encoder and split train test valid\n",
    "class ProofStep(Dataset):\n",
    "    \n",
    "    def __init__(self, df, tokenizer):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.df = df\n",
    "#         self.attn_masks = []\n",
    "#             self.attn_masks.append(torch.tensor(encodings_dict['attention_mask']))\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        toks = self.tokenizer.encode(' <|GOAL|>' + self.df.cleaned_goal.iloc[idx] + ' <|PROOFSTEP|>' + self.df.human_tactic_code.iloc[idx] + ' <|endoftext|>') \n",
    "        return torch.tensor(toks)\n",
    "#         print(' <|GOAL|>' + self.df.cleaned_goal.iloc[idx] + ' <|PROOFSTEP|>' + self.df.human_tactic_code.iloc[idx])\n",
    "#         return toks#, self.attn_masks[idx] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (AdamW, \n",
    "                          get_linear_schedule_with_warmup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "147,271 training samples\n",
      "6,786 validation samples\n",
      "6,317 test samples\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import RandomSampler, SequentialSampler\n",
    "# Split into train, validation and test set: 80 - 5 - 15\n",
    "\n",
    "df_train = df[df.split == 'train']\n",
    "df_train.reset_index()\n",
    "df_valid = df[df.split == 'valid']\n",
    "df_valid.reset_index()\n",
    "df_test = df[df.split == 'test']\n",
    "df_test.reset_index()\n",
    "\n",
    "train_dataset = ProofStep(df_train, enc)\n",
    "val_dataset = ProofStep(df_valid, enc)\n",
    "test_dataset = ProofStep(df_test, enc)\n",
    "\n",
    "print('{:>5,} training samples'.format(len(train_dataset)))\n",
    "print('{:>5,} validation samples'.format(len(val_dataset)))\n",
    "print('{:>5,} test samples'.format(len(test_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.utils.data import random_split\n",
    "# from torch.utils.data import RandomSampler, SequentialSampler\n",
    "\n",
    "# dataset = ProofStep(df, enc)\n",
    "\n",
    "# # Split into train, validation and test set: 80 - 5 - 15\n",
    "# train_size = 80/100 * len(dataset)\n",
    "# val_size = 5/100 * len(dataset)\n",
    "# test_size = len(dataset - train)\n",
    "\n",
    "# train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "# print('{:>5,} training samples'.format(train_size))\n",
    "# print('{:>5,} validation samples'.format(val_size))\n",
    "# print('{:>5,} test samples'.format(test_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "text=\"It was a bright cold day in April.\"\n",
    "quiet=False\n",
    "nsamples=1\n",
    "unconditional=False\n",
    "batch_size=1\n",
    "gradient_acc_steps = 32\n",
    "length=-1\n",
    "temperature=0.7\n",
    "top_k=40\n",
    "\n",
    "epochs=21\n",
    "lr=1e-5 #0.0014\n",
    "warmup_steps=200\n",
    "epsilon = 1e-8\n",
    "\n",
    "output_dir=\"./models\" \n",
    "output_prefix=\"proofstep-named\"\n",
    "test_mode=False\n",
    "save_model_on_epoch=True\n",
    "sample_every = 100 #sample output every 100 steps\n",
    "\n",
    "# device=torch.device(\"cpu\")\n",
    "# model = model.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import RandomSampler, SequentialSampler\n",
    "\n",
    "# Create the DataLoaders for our datasets.\n",
    "# We'll take training samples in random order. \n",
    "train_dataloader = DataLoader(\n",
    "            train_dataset,  # The training samples.\n",
    "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
    "            batch_size = batch_size # Trains with this batch size.\n",
    "        )\n",
    "# For validation and test the order doesn't matter, so we'll just read them sequentially.\n",
    "validation_dataloader = DataLoader(\n",
    "            val_dataset, # The validation samples.\n",
    "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
    "            batch_size = batch_size # Evaluate with this batch size.\n",
    "        )\n",
    "test_dataloader = DataLoader(\n",
    "            test_dataset, # The validation samples.\n",
    "            sampler = SequentialSampler(test_dataset), # Pull out batches sequentially.\n",
    "            batch_size = batch_size # Evaluate with this batch size.\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# home = expanduser(\"~\")\n",
    "# state_dict = torch.load(os.path.join(home, 'data/GPT2/gpt2-pytorch_model.bin'), map_location='cpu' if not torch.cuda.is_available() else None)\n",
    "\n",
    "# old_keys = []\n",
    "# new_keys = []\n",
    "# for key in state_dict.keys():\n",
    "#     new_key = None\n",
    "#     if key.endswith(\".g\"):\n",
    "#         new_key = key[:-2] + \".weight\"\n",
    "#     elif key.endswith(\".b\"):\n",
    "#         new_key = key[:-2] + \".bias\"\n",
    "#     elif key.endswith(\".w\"):\n",
    "#         new_key = key[:-2] + \".weight\"\n",
    "#     if new_key:\n",
    "#         old_keys.append(key)\n",
    "#         new_keys.append(new_key)\n",
    "# for old_key, new_key in zip(old_keys, new_keys):\n",
    "#     state_dict[new_key] = state_dict.pop(old_key)\n",
    "# # model.load_state_dict(state_dict)\n",
    "# missing_keys = []\n",
    "# unexpected_keys = []\n",
    "# error_msgs = []\n",
    "# # copy state_dict so _load_from_state_dict can modify it\n",
    "# metadata = getattr(state_dict, \"_metadata\", None)\n",
    "# state_dict = state_dict.copy()\n",
    "# if metadata is not None:\n",
    "#     state_dict._metadata = metadata\n",
    "\n",
    "# def load(module, prefix=\"\"):\n",
    "#     local_metadata = {} if metadata is None else metadata.get(prefix[:-1], {})\n",
    "#     module._load_from_state_dict(\n",
    "#         state_dict, prefix, local_metadata, True, missing_keys, unexpected_keys, error_msgs\n",
    "#     )\n",
    "#     for name, child in module._modules.items():\n",
    "#         if child is not None:\n",
    "#             load(child, prefix + name + \".\")\n",
    "\n",
    "# start_model = model\n",
    "# if hasattr(model, \"transformer\") and all(not s.startswith('transformer.') for s in state_dict.keys()):\n",
    "#     start_model = model.transformer\n",
    "# load(start_model, prefix=\"\")\n",
    "\n",
    "# model.set_tied()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of current stats file: 20\n",
      "\n",
      "[] [] ['size mismatch for wte.weight: copying a param with shape torch.Size([50257, 768]) from checkpoint, the shape in current model is torch.Size([50259, 768]).']\n",
      "Checkpoint not found, starting from epoch #0, min_val_loss of inf.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checkpoint model for resuming\n",
    "\n",
    "import os\n",
    "from os.path import isfile, join\n",
    "import re\n",
    "import json\n",
    "\n",
    "def load_pretrained_GPT2(model):\n",
    "    home = expanduser(\"~\")\n",
    "    state_dict = torch.load(os.path.join(home, 'data/GPT2/gpt2-pytorch_model.bin'), map_location='cpu' if not torch.cuda.is_available() else None)\n",
    "\n",
    "    old_keys = []\n",
    "    new_keys = []\n",
    "    for key in state_dict.keys():\n",
    "        new_key = None\n",
    "        if key.endswith(\".g\"):\n",
    "            new_key = key[:-2] + \".weight\"\n",
    "        elif key.endswith(\".b\"):\n",
    "            new_key = key[:-2] + \".bias\"\n",
    "        elif key.endswith(\".w\"):\n",
    "            new_key = key[:-2] + \".weight\"\n",
    "        if new_key:\n",
    "            old_keys.append(key)\n",
    "            new_keys.append(new_key)\n",
    "    for old_key, new_key in zip(old_keys, new_keys):\n",
    "        state_dict[new_key] = state_dict.pop(old_key)\n",
    "    # model.load_state_dict(state_dict)\n",
    "    missing_keys = []\n",
    "    unexpected_keys = []\n",
    "    error_msgs = []\n",
    "    # copy state_dict so _load_from_state_dict can modify it\n",
    "    metadata = getattr(state_dict, \"_metadata\", None)\n",
    "    state_dict = state_dict.copy()\n",
    "    if metadata is not None:\n",
    "        state_dict._metadata = metadata\n",
    "\n",
    "    def load(module, prefix=\"\"):\n",
    "        local_metadata = {} if metadata is None else metadata.get(prefix[:-1], {})\n",
    "        module._load_from_state_dict(\n",
    "            state_dict, prefix, local_metadata, True, missing_keys, unexpected_keys, error_msgs\n",
    "        )\n",
    "        for name, child in module._modules.items():\n",
    "            if child is not None:\n",
    "                load(child, prefix + name + \".\")\n",
    "\n",
    "    start_model = model\n",
    "    if hasattr(model, \"transformer\") and all(not s.startswith('transformer.') for s in state_dict.keys()):\n",
    "        start_model = model.transformer\n",
    "    load(start_model, prefix=\"\")\n",
    "\n",
    "    model.set_tied()\n",
    "    with torch.no_grad():\n",
    "        model.transformer.wte.weight[:50257, :] = state_dict['wte.weight']\n",
    "    print(missing_keys, unexpected_keys, error_msgs)\n",
    "\n",
    "def load_checkpoint(config, output_dir, output_prefix, new_train = 0):\n",
    "    files = []\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "        print(f\"Creating output directory {output_dir}\")\n",
    "    else:    \n",
    "        files = [f for f in os.listdir(output_dir) if isfile(join(output_dir, f))]\n",
    "\n",
    "    # Find training stats\n",
    "    stats_filename = \"stats.json\"\n",
    "    if stats_filename in files:\n",
    "        with open(os.path.join(output_dir, stats_filename), 'r') as f:\n",
    "            training_stats = json.load(f)\n",
    "    else:\n",
    "        training_stats = []\n",
    "    print(f\"Length of current stats file: {len(training_stats)}\\n\")\n",
    "\n",
    "    # Find checkpoints\n",
    "    r = re.compile(f\"{output_prefix}-[0-9]*.pt\")\n",
    "    model_files = list(filter(r.match, files))\n",
    "    epochs_list = [int(x[ len(output_prefix)+1 : -3 ]) for x in model_files]\n",
    "    model = GPT2LMHeadModel(config)\n",
    "    if epochs_list:\n",
    "        current_epoch = max(epochs_list)\n",
    "        min_val_loss = min([x[\"Valid. Loss\"] for x in training_stats])\n",
    "        model.load_state_dict(\n",
    "                torch.load(os.path.join(output_dir, f\"{output_prefix}-{current_epoch}.pt\"))\n",
    "        )\n",
    "        print(f\"Checkpoint #{current_epoch} found, with min_val_loss of {min_val_loss:.3f}, resuming.\")\n",
    "    else:\n",
    "        current_epoch = 0\n",
    "        min_val_loss = float(\"inf\")\n",
    "        load_pretrained_GPT2(model)\n",
    "        print(f\"Checkpoint not found, starting from epoch #{current_epoch}, min_val_loss of {min_val_loss:.3f}.\")\n",
    "    return model, current_epoch, min_val_loss, training_stats\n",
    "\n",
    "config = GPT2Config()\n",
    "config.vocab_size += 2 # 2 new tokens\n",
    "model, current_epoch, min_val_loss, training_stats = load_checkpoint(config, output_dir, output_prefix)\n",
    "type(model) == GPT2LMHeadModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of warmup steps: 200\n",
      "Total steps: 96663\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "model = model.cuda()\n",
    "\n",
    "# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = lr,\n",
    "                  eps = epsilon\n",
    "                )\n",
    "\n",
    "# Total number of training steps is [number of batches] x [number of epochs]. \n",
    "# (Note that this is not the same as the number of training samples).\n",
    "total_steps = (len(train_dataloader) // gradient_acc_steps + 1) * epochs\n",
    "\n",
    "# Create the learning rate scheduler.\n",
    "# This changes the learning rate as the training loop progresses\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = warmup_steps, \n",
    "                                            num_training_steps = total_steps)\n",
    "\n",
    "print(f\"Number of warmup steps: {warmup_steps}\\nTotal steps: {total_steps}\")\n",
    "type(model) == GPT2LMHeadModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "def format_time(elapsed):\n",
    "    return str(datetime.timedelta(seconds=int(round((elapsed)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import  matplotlib.pyplot as plt\n",
    "# For sampling\n",
    "def display_attn_and_confidence(model, context_text):\n",
    "    activation = {}\n",
    "    def get_activation(name):\n",
    "        def hook(model, input, output):\n",
    "            activation[name] = output[2].detach()\n",
    "        return hook\n",
    "    \n",
    "    context = enc.encode(context_text)\n",
    "    context = torch.tensor(context, device=device, dtype=torch.long).unsqueeze(0)\n",
    "\n",
    "    # Getting attention outputs\n",
    "    handles = [\n",
    "        model.transformer.h[x].attn.register_forward_hook(get_activation(f'attn_{x}'))\n",
    "            for x in range(12)\n",
    "    ]\n",
    "\n",
    "    # Display next token confidence\n",
    "    prev = context\n",
    "    with torch.no_grad():\n",
    "        logits, past = model(prev)\n",
    "        logits = logits[:, -1, :] / 0.7\n",
    "        logits = top_k_logits(logits, k=10)\n",
    "        log_probs = F.softmax(logits, dim=-1)\n",
    "        values, prev = torch.topk(log_probs, k=10, dim=-1)\n",
    "\n",
    "    prev = prev.tolist()\n",
    "    for i in range(len(prev[0])):\n",
    "        text = enc.decode([prev[0][i]])\n",
    "        print(f\"{text} -> {values[0][i].item()}\")\n",
    "    [handle.remove() for handle in handles]\n",
    "\n",
    "    # Visualize attention maps\n",
    "    idx = 0\n",
    "    input_data = np.arange(context.shape[-1])\n",
    "    attn_maps = [[(torch.sum(activation[f'attn_{x}'], dim=1)/12).detach().cpu().numpy() \n",
    "                         for x in range(12)]]\n",
    "    num_heads = 12\n",
    "    num_layers = 1\n",
    "    seq_len = input_data.shape[0]\n",
    "    fig_size = 4 if num_heads == 1 else 3\n",
    "    fig, ax = plt.subplots(num_layers, num_heads, figsize=(num_heads*fig_size, num_layers*fig_size))\n",
    "    if num_layers == 1:\n",
    "        ax = [ax]\n",
    "    if num_heads == 1:\n",
    "        ax = [[a] for a in ax]\n",
    "    for row in range(num_layers):\n",
    "        for column in range(num_heads):        \n",
    "            im = ax[row][column].imshow(attn_maps[row][column][0], origin='upper', vmin=0, vmax=1, cmap='bone')\n",
    "            ax[row][column].set_xticks(list(range(seq_len)))\n",
    "            ax[row][column].set_xticklabels(input_data.tolist())\n",
    "            ax[row][column].set_yticks(list(range(seq_len)))\n",
    "            ax[row][column].set_yticklabels(input_data.tolist())\n",
    "            ax[row][column].set_title(f\"Layer {column+1}\")\n",
    "            context_words = [enc.decode([x]).strip(' ') for x in context.cpu().numpy()[0]]\n",
    "            if column == 0:\n",
    "                ax[row][column].set_yticklabels(context_words)\n",
    "            ax[row][column].set_xticklabels(context_words, rotation=90)\n",
    "\n",
    "    fig.subplots_adjust(hspace=0.6)\n",
    "    fig.subplots_adjust(right=0.9)\n",
    "    cbar_ax = fig.add_axes([0.91, 0.15, 0.02, 0.7])\n",
    "    fig.colorbar(im, cax=cbar_ax)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex as re\n",
    "\n",
    "# Wandb manage model weights statistics \n",
    "if is_experimenting:\n",
    "    wandb.watch(model)\n",
    "\n",
    "total_t0 = time.time()\n",
    "# training_stats = []\n",
    "# min_val_loss = float('inf')\n",
    "\n",
    "for epoch_i in range(current_epoch+1, epochs):\n",
    "\n",
    "    # ========================================\n",
    "    #               Training\n",
    "    # ========================================\n",
    "\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i, epochs))\n",
    "    print('Training...')\n",
    "    \n",
    "    t0 = time.time()\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "    loss = 0\n",
    "    for step, batch in tqdm(enumerate(train_dataloader)):\n",
    "        \n",
    "        b_input_ids = batch[0].to(device).unsqueeze(0) # Need to have 2 sizes\n",
    "        print(b_input_ids.shape)\n",
    "        if step >= 3:\n",
    "            raise\n",
    "#         print(enc.decode(b_input_ids.cpu().numpy()[0]))\n",
    "        \n",
    "#         b_labels = batch[0].to(device)\n",
    "#         b_masks = batch[1].to(device)\n",
    "\n",
    "        model.zero_grad()        \n",
    "        outputs = model(b_input_ids,\n",
    "                        lm_labels=b_input_ids,) \n",
    "#                           attention_mask=b_masks,)\\\n",
    "#         print(outputs)\n",
    "#         raise\n",
    "        loss = outputs[0] \n",
    "#         print(loss)\n",
    "#         raise\n",
    "        batch_loss = loss.item()\n",
    "        total_train_loss += batch_loss\n",
    "        loss /= gradient_acc_steps \n",
    "        \n",
    "        # Attention table\n",
    "        \n",
    "        # Get sample every x batches.\n",
    "        if (step/gradient_acc_steps) % sample_every == 0 and not step == 0:\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            print('  Step {:>5,}  of  {:>5,}. Loss: {:>5,}.   Elapsed: {:}.'.format(step, len(train_dataloader), batch_loss, elapsed))\n",
    "            model.eval()\n",
    "            \n",
    "            # Generate a sample sequence\n",
    "            context_text = \" <|GOAL|>α : Type u,\\n_inst_1 : linear_order α,\\na b : α\\n⊢ linear_order.min a b ≤ b <|PROOFSTEP|>\" # Answer: 'min_tac a b'\n",
    "            context_tokens = enc.encode(context_text)\n",
    "            out = sample_sequence(\n",
    "                model=model, length=200,\n",
    "                context=context_tokens,\n",
    "                batch_size=1,\n",
    "                temperature=0.95, \n",
    "                top_k=50, device=device\n",
    "            )\n",
    "            out = out[:, len(context_tokens):].tolist()\n",
    "            text = enc.decode(out[0])\n",
    "            print(f\"Sample:{text}\")\n",
    "\n",
    "            # Show attention table\n",
    "            display_attn_and_confidence(model, context_text)\n",
    "            \n",
    "            model.train()\n",
    "        \n",
    "        # Update\n",
    "        loss.backward()\n",
    "        \n",
    "        if (step+1) % gradient_acc_steps == 0 or (step + 1 == len(train_dataloader)):            \n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            if is_experimenting:\n",
    "                wandb.log(\n",
    "                    {\n",
    "                        \"epoch\": epoch_i,\n",
    "                        'batch_loss': batch_loss\n",
    "                    }\n",
    "                )\n",
    "                # wandb log attention table\n",
    "    #             wandb.join()\n",
    "        \n",
    "    # Report training\n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)       \n",
    "    training_time = format_time(time.time() - t0)\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"  Training epoch took: {:}\".format(training_time))\n",
    "        \n",
    "    # ========================================\n",
    "    #               Validation\n",
    "    # ========================================\n",
    "    \n",
    "    print(\"\")\n",
    "    print(\"Running Validation...\")\n",
    "\n",
    "    t0 = time.time()\n",
    "    model.eval()\n",
    "    total_eval_loss = 0\n",
    "    nb_eval_steps = 0\n",
    "    # Evaluate data for one epoch\n",
    "    for batch in validation_dataloader:\n",
    "        \n",
    "        b_input_ids = batch[0].to(device).unsqueeze(0)\n",
    "#         b_labels = batch[0].to(device)\n",
    "#         b_masks = batch[1].to(device)  \n",
    "        \n",
    "        with torch.no_grad():        \n",
    "            outputs  = model(b_input_ids, \n",
    "                             lm_labels=b_input_ids,) \n",
    "#                            token_type_ids=None, \n",
    "#                              attention_mask = b_masks,          \n",
    "            loss = outputs[0]  \n",
    "        batch_loss = loss.item()\n",
    "        total_eval_loss += batch_loss        \n",
    "\n",
    "    # Report validation\n",
    "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
    "    if min_val_loss > avg_val_loss:\n",
    "        min_val_loss = avg_val_loss\n",
    "    validation_time = format_time(time.time() - t0)    \n",
    "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
    "    print(\"  Validation took: {:}\".format(validation_time))\n",
    "    \n",
    "    # Record all statistics from this epoch.\n",
    "    training_stats.append(\n",
    "        {\n",
    "            'epoch': epoch_i + 1,\n",
    "            'Training Loss': avg_train_loss,\n",
    "            'Valid. Loss': avg_val_loss,\n",
    "            'Training Time': training_time,\n",
    "            'Validation Time': validation_time\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    if save_model_on_epoch:\n",
    "        # Save training stats\n",
    "        with open(os.path.join(output_dir, \"stats.json\"), 'w') as f:\n",
    "            json.dump(training_stats, f)\n",
    "        # Save two files: current best model and current epoch model\n",
    "        if avg_val_loss < min_val_loss:\n",
    "            torch.save(\n",
    "                model.state_dict(),\n",
    "                os.path.join(output_dir, f\"{output_prefix}-best.pt\"),\n",
    "            )\n",
    "        torch.save(\n",
    "            model.state_dict(),\n",
    "            os.path.join(output_dir, f\"{output_prefix}-{epoch_i}.pt\"),\n",
    "        )\n",
    "        if epoch_i > 1:\n",
    "            # Remove previous checkpoint\n",
    "            os.remove(os.path.join(output_dir, f\"{output_prefix}-{epoch_i-1}.pt\"))\n",
    "\n",
    "print(\"\")\n",
    "print(\"Training complete!\")\n",
    "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))\n",
    "type(model) == GPT2LMHeadModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to generate lyrics for test set, get loss, evaluate on persplexity, bleu and rougev \n",
    "# Want to see model's confidence knowing context as well -> attention "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to check if exists directory, if no, try to create\n",
    "# Try save a dummy model and delete it\n",
    "# These checks are done at the start of notebook\n",
    "# Resume: Check if the directory has a checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of current stats file: 40\n",
      "\n",
      "Checkpoint #20 found, with min_val_loss of 0.961, resuming.\n"
     ]
    }
   ],
   "source": [
    "config = GPT2Config()\n",
    "# model = GPT2LMHeadModel(config)\n",
    "config.vocab_size += 2\n",
    "model, current_epoch, min_val_loss, training_stats = load_checkpoint(config, output_dir, output_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_nested_tuple(x):\n",
    "    if type(x) == tuple:\n",
    "        print(len(x))\n",
    "        for y in x:\n",
    "            print_nested_tuple(y)\n",
    "    else:\n",
    "        print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6317it [01:25, 73.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Test Loss: 1.02\n",
      "  Test took: 0:01:25\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'contexts' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-df607ab225dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"  Test Loss: {0:.2f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mavg_test_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#2.25\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"  Test took: {:}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontexts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_lyrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerated_lyrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'contexts' is not defined"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "#               Test\n",
    "# ========================================\n",
    "\n",
    "length = 20\n",
    "temperature=0.7\n",
    "top_k=40\n",
    "model.cuda()\n",
    "\n",
    "print(\"\")\n",
    "print(\"Running Test...\")\n",
    "\n",
    "t0 = time.time()\n",
    "model.eval()\n",
    "total_eval_loss = 0\n",
    "# Evaluate data for one epoch\n",
    "for i, batch in tqdm(enumerate(test_dataloader)):\n",
    "    \n",
    "    b_input_ids = batch.to(device).view(batch_size, -1)\n",
    "#     print(b_input_ids.shape)\n",
    "#         b_labels = batch[0].to(device)\n",
    "#         b_masks = batch[1].to(device)  \n",
    "\n",
    "    with torch.no_grad():   \n",
    "          \n",
    "        # Find loss\n",
    "        loss, _, _  = model(b_input_ids, \n",
    "                         lm_labels=b_input_ids,)\n",
    "    \n",
    "    batch_loss = loss.item()\n",
    "    total_eval_loss += batch_loss\n",
    "    \n",
    "#     print(f\"Outputs have {len(outputs)} items:\\noutputs[0]={outputs[0]}\\noutputs[1]={outputs[1].shape}\\noutputs[2]={[x.shape for x in outputs[2]]}\")\n",
    "#     if i >= 3:\n",
    "#         break\n",
    "    \n",
    "# Report test\n",
    "avg_test_loss = total_eval_loss / len(test_dataloader)\n",
    "test_time = format_time(time.time() - t0)    \n",
    "print(\"  Test Loss: {0:.2f}\".format(avg_test_loss)) #2.25\n",
    "print(\"  Test took: {:}\".format(test_time))\n",
    "len(contexts), len(true_lyrics), len(generated_lyrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "contexts[7]+\"|||\"+true_lyrics[7], contexts[7]+\"|||\"+generated_lyrics[7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# #Finish the sentences when there is a point, remove after that\n",
    "final=[]\n",
    "\n",
    "for i in range(len(true_lyrics)):\n",
    "    to_remove = generated_lyrics[i].split('.')[-1]\n",
    "    final.append(generated_lyrics[i].replace(to_remove,''))\n",
    "\n",
    "# test_set['Generated_lyrics'] = final\n",
    "# test_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Using BLEU score to compare the real sentences with the generated ones\n",
    "import statistics\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "\n",
    "scores=[]\n",
    "\n",
    "for i in range(len(true_lyrics)):\n",
    "    reference = [true_lyrics[i]]\n",
    "    candidate = final[i]\n",
    "    scores.append(sentence_bleu(reference, candidate))\n",
    "\n",
    "statistics.mean(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Rouge score\n",
    "from rouge import Rouge\n",
    "rouge=Rouge()\n",
    "\n",
    "rouge.get_scores(final, true_lyrics, avg=True, ignore_empty=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.utils.data import DataLoader\n",
    "# from torch.utils.data import RandomSampler, SequentialSampler\n",
    "\n",
    "# # Create the DataLoaders for our datasets.\n",
    "# # We'll take training samples in random order. \n",
    "# train_dataloader = DataLoader(\n",
    "#             train_dataset,  # The training samples.\n",
    "#             sampler = RandomSampler(train_dataset), # Select batches randomly\n",
    "#             batch_size = batch_size # Trains with this batch size.\n",
    "#         )\n",
    "# # For validation and test the order doesn't matter, so we'll just read them sequentially.\n",
    "# validation_dataloader = DataLoader(\n",
    "#             val_dataset, # The validation samples.\n",
    "#             sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
    "#             batch_size = batch_size # Evaluate with this batch size.\n",
    "#         )\n",
    "# test_dataloader = DataLoader(\n",
    "#             test_dataset, # The validation samples.\n",
    "#             sampler = SequentialSampler(test_dataset), # Pull out batches sequentially.\n",
    "#             batch_size = batch_size # Evaluate with this batch size.\n",
    "#         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each entry of the matrix is a row in attention table (for wandb logging)\n",
    "        # Log wandb\n",
    "#         columns=[\"s_ind\", \"t_ind\", \"s_word\", \"t_word\", \"attn\"]\n",
    "#         attn_table = wandb.Table(columns=columns)\n",
    "#         temp = context_text.split(\" \")\n",
    "#         for s_ind in range(seq_len):\n",
    "#                 attn_table.add_data(s_ind, t_ind, temp[s_ind], temp[t_ind], attn_maps[row][column][0][s_ind][t_ind])\n",
    "#         wandb.log({\"attn_table\": attn_table})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
